{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most disussed person under each sport category in New York Times between 2010 and 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rainbow\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: DeprecationWarning: This method will be removed in future versions.  Use 'parser.read_file()' instead.\n"
     ]
    }
   ],
   "source": [
    "import requests, configparser, os, sys, json, glob\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rainbow\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: DeprecationWarning: This method will be removed in future versions.  Use 'parser.read_file()' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 100\n",
      "nytimes_data\\Sports\\Pro Football\\article\\585721ba95d0e03926076af2.json exists\n",
      "nytimes_data\\Sports\\Soccer\\article\\585721ba95d0e03926076af1.json exists\n",
      "nytimes_data\\Sports\\College Basketball\\article\\5857206095d0e03926076aed.json exists\n",
      "nytimes_data\\Sports\\College Basketball\\article\\58571ef695d0e03926076aeb.json exists\n",
      "nytimes_data\\Sports\\Pro Basketball\\article\\58571d8c95d0e03926076aea.json exists\n",
      "nytimes_data\\Sports\\Baseball\\article\\58571d6e95d0e03926076ae7.json exists\n",
      "nytimes_data\\Sports\\College Basketball\\article\\58571cd695d0e03926076ae6.json exists\n",
      "nytimes_data\\Sports\\College Basketball\\article\\58571b7095d0e03926076ae3.json exists\n",
      "nytimes_data\\Sports\\Pro Basketball\\article\\58571ac495d0e03926076ae2.json exists\n",
      "nytimes_data\\Sports\\Pro Football\\article\\5857168195d0e03926076ada.json exists\n",
      "page 101\n",
      "nytimes_data\\Sports\\Hockey\\article\\5857151995d0e03926076ad8.json exists\n",
      "nytimes_data\\Sports\\College Basketball\\article\\58570b4595d0e03926076ac9.json exists\n",
      "nytimes_data\\Sports\\College Basketball\\article\\58570a9595d0e03926076ac7.json exists\n",
      "nytimes_data\\Sports\\College Basketball\\article\\5857092495d0e03926076ac5.json exists\n",
      "nytimes_data\\Sports\\Soccer\\article\\5857086d95d0e03926076ac4.json exists\n",
      "nytimes_data\\Sports\\Pro Football\\article\\585704e795d0e03926076ac0.json exists\n",
      "nytimes_data\\Sports\\Pro Football\\article\\5857043b95d0e03926076abf.json exists\n",
      "nytimes_data\\Sports\\Pro Football\\article\\5857022295d0e03926076abd.json exists\n",
      "nytimes_data\\Sports\\College Basketball\\article\\5857017095d0e03926076abb.json exists\n",
      "nytimes_data\\Sports\\Tennis\\article\\5857016f95d0e03926076aba.json exists\n",
      "page 102\n",
      "Caught this error: Exception('API rate limit exceeded',)\n"
     ]
    }
   ],
   "source": [
    "# Collecting data\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.readfp(open(r'config.txt'))\n",
    "\n",
    "i = 100\n",
    "try:\n",
    "    while i < 120:\n",
    "        print('page '+str(i))\n",
    "        uri_path_list = []\n",
    "        sports_list = []\n",
    "        category_list = []\n",
    "\n",
    "        for link in config['uri']:\n",
    "            uri_path_list.append(config.get('uri',link))\n",
    "            break;\n",
    "\n",
    "        directory = config.get('directory_path','directory')\n",
    "        sub_directory = config.get('directory_path','sub_directory')    \n",
    "\n",
    "        for key in config['api_key']:\n",
    "            uri_path_list.append('?api_key='+config.get('api_key',key))\n",
    "            break;                \n",
    "\n",
    "        for param in config['parameters']:\n",
    "            #print(param)\n",
    "            uri_path_list.append('&'+param+'='+config.get('parameters',param))\n",
    "        uri_path_list.append('&page=' + str(i) )\n",
    "\n",
    "        uri_path = ''.join(uri_path_list);\n",
    "        resp = requests.get(uri_path)\n",
    "        request_data = (resp).json();  \n",
    "        if 'errors' in request_data.keys():\n",
    "            raise Exception(request_data['errors'])\n",
    "        elif 'message' in request_data.keys():\n",
    "            raise Exception(request_data['message'])\n",
    "\n",
    "        #print(directory)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        if not os.path.exists(directory+'\\\\'+sub_directory):\n",
    "            os.makedirs(directory+'\\\\'+sub_directory)\n",
    "\n",
    "        #print('Starting to store json files for sports.')    \n",
    "\n",
    "        try:    \n",
    "            if( 'response' in request_data.keys() ):\n",
    "                response = request_data['response']\n",
    "                if( 'docs' in response.keys() ):\n",
    "                    docs = response['docs']        \n",
    "                    for doc in docs:\n",
    "                        if( 'subsection_name' in doc.keys() ):\n",
    "                            sport = doc.get('subsection_name')\n",
    "                            if(sport != None):\n",
    "                                sport_path = directory+'\\\\'+sub_directory+'\\\\'+sport;\n",
    "                                if not os.path.exists(sport_path):\n",
    "                                    sports_list.append(sport)\n",
    "                                    os.makedirs(sport_path)\n",
    "\n",
    "                                if( 'document_type' in doc.keys() ):\n",
    "                                    category = doc.get('document_type')\n",
    "                                    if(category != None):\n",
    "                                        category_path = sport_path + '\\\\' + category;\n",
    "                                        if not os.path.exists(category_path):\n",
    "                                            category_list.append(category)\n",
    "                                            os.makedirs(category_path)\n",
    "\n",
    "                                        # put doc data in to correspoding json file inside sport\n",
    "                                        file_path = category_path+'\\\\'+doc.get('_id')+\".json\"\n",
    "                                        if not os.path.exists(file_path):\n",
    "                                            print(file_path+' writing')\n",
    "                                            with open(file_path, \"w\") as outfile:\n",
    "                                                json.dump(doc, outfile, indent=4)\n",
    "                                        else: \n",
    "                                            print(file_path+' exists')\n",
    "        except ValueError:\n",
    "            print(\"error :\", sys.exc_info()[0])\n",
    "        i = i + 1\n",
    "    print('Storing json files for sports completed.')\n",
    "except Exception as error:\n",
    "    print('Caught this error: ' + repr(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most discussed people in each sports in New York Times\n",
      "\n",
      "Auto Racing:\n",
      "1 - Antonio\n",
      "1 - Giovinazzi\n",
      "1 - Jost\n",
      "1 - Capito\n",
      "1 - Ron\n",
      "1 - Dennis\n",
      "1 - Lewis\n",
      "1 - Hamilton\n",
      "\n",
      "Baseball:\n",
      "2 - Edwin\n",
      "2 - Encarnacion\n",
      "2 - Outfielder\n",
      "1 - Shortstop\n",
      "1 - Jimmy\n",
      "1 - Rollins\n",
      "1 - Daniel\n",
      "1 - Hudson\n",
      "1 - Pitcher\n",
      "1 - Nick\n",
      "\n",
      "College Basketball:\n",
      "13 - State\n",
      "5 - Texas\n",
      "4 - Kentucky\n",
      "4 - Brown\n",
      "4 - Kelsey\n",
      "4 - Florida\n",
      "4 - Saint\n",
      "4 - Josh\n",
      "3 - Bob\n",
      "3 - Huggins\n",
      "\n",
      "College Football:\n",
      "3 - Mike\n",
      "3 - Ohio\n",
      "3 - State\n",
      "3 - Clemson\n",
      "3 - Dabo\n",
      "3 - Swinney\n",
      "3 - Williams\n",
      "2 - Leonard\n",
      "2 - Fournette\n",
      "2 - Bob\n",
      "\n",
      "Cricket:\n",
      "8 - Sri\n",
      "8 - Lanka\n",
      "6 - Steve\n",
      "3 - Smith\n",
      "3 - Stephen\n",
      "2 - Karun\n",
      "2 - Nair\n",
      "2 - Virat\n",
      "2 - Kohli\n",
      "2 - Cook\n",
      "\n",
      "Cycling:\n",
      "3 - Team\n",
      "3 - Bradley\n",
      "3 - Wiggins\n",
      "2 - Sky\n",
      "1 - Dave\n",
      "1 - Brailsford\n",
      "1 - Cycling\n",
      "1 - Stephen\n",
      "1 - Park\n",
      "1 - GB\n",
      "\n",
      "Golf:\n",
      "2 - Tiger\n",
      "2 - Woods\n",
      "1 - Solheim\n",
      "1 - Cup\n",
      "1 - Helen\n",
      "1 - Alfredsson\n",
      "1 - Jack\n",
      "1 - Nicklaus\n",
      "1 - Notah\n",
      "1 - Begay\n",
      "\n",
      "Hockey:\n",
      "9 - Jaromir\n",
      "7 - Jagr\n",
      "4 - John\n",
      "3 - Tortorella\n",
      "3 - Mike\n",
      "2 - Henrik\n",
      "2 - Coach\n",
      "2 - Ryan\n",
      "2 - Bill\n",
      "2 - Aleksander\n",
      "\n",
      "Olympics:\n",
      "2 - Hickey\n",
      "1 - Pat\n",
      "1 - Skeleton\n",
      "1 - Federation\n",
      "1 - Patrick\n",
      "\n",
      "Pro Basketball:\n",
      "8 - Anthony\n",
      "5 - Carmelo\n",
      "4 - Clippers\n",
      "4 - Paul\n",
      "3 - Bradley\n",
      "3 - Beal\n",
      "3 - Isaiah\n",
      "3 - Thomas\n",
      "3 - Blake\n",
      "3 - James\n",
      "\n",
      "Pro Football:\n",
      "5 - Doug\n",
      "4 - Aaron\n",
      "4 - Tom\n",
      "4 - Ben\n",
      "4 - Robert\n",
      "3 - Mike\n",
      "3 - Bradley\n",
      "3 - Brady\n",
      "3 - Cam\n",
      "3 - Newton\n",
      "\n",
      "Rugby:\n",
      "3 - Eddie\n",
      "3 - Jones\n",
      "2 - George\n",
      "1 - Dylan\n",
      "1 - Hartley\n",
      "1 - Northampton\n",
      "1 - Saints\n",
      "1 - North's\n",
      "1 - Leicester\n",
      "1 - Charlie\n",
      "\n",
      "Sailing:\n",
      "1 - Adrienne\n",
      "1 - Cahalan\n",
      "\n",
      "Skiing:\n",
      "1 - Anna\n",
      "1 - Holmlund\n",
      "1 - Sweden\n",
      "\n",
      "Soccer:\n",
      "17 - City\n",
      "13 - Manchester\n",
      "9 - Jose\n",
      "8 - Liverpool\n",
      "7 - Everton\n",
      "7 - Tottenham\n",
      "7 - Juergen\n",
      "6 - Chelsea\n",
      "6 - Antonio\n",
      "6 - United\n",
      "\n",
      "Tennis:\n",
      "5 - Petra\n",
      "5 - Kvitova\n",
      "4 - Andy\n",
      "4 - Murray\n",
      "4 - Ivanovic\n",
      "3 - Ana\n",
      "2 - Australian\n",
      "2 - Open\n",
      "2 - Roger\n",
      "1 - Federer\n"
     ]
    }
   ],
   "source": [
    "#import operator\n",
    "\n",
    "search_path = directory+'/'+sub_directory+'/'\n",
    "sports_results = dict()\n",
    "MAX_RESULTS = 10\n",
    "directory = config.get('directory_path','directory')\n",
    "sub_directory = config.get('directory_path','sub_directory')    \n",
    "\n",
    "for x in os.walk(directory+'/'+sub_directory):\n",
    "    sports_list = x[1]\n",
    "    break;\n",
    "\n",
    "for sport in sports_list:\n",
    "    sport_path = search_path+sport+'/*/*.json'\n",
    "    top_word = dict()\n",
    "    for file in glob.glob(sport_path):\n",
    "        with open(file, 'r') as f:\n",
    "            #print(file)\n",
    "            data = json.load(f)\n",
    "            paragraph = data['lead_paragraph']            \n",
    "            tagged_sent = pos_tag((paragraph.replace('.','').replace(',','')).split())\n",
    "            \n",
    "            tri = [chunk for chunk in ne_chunk(tagged_sent) if isinstance(chunk, Tree)]\n",
    "            named_entities = []\n",
    "            for t in tri:\n",
    "                if t.label() == 'PERSON':\n",
    "                    for c in t:\n",
    "                        named_entities.append(c[0])\n",
    "            \n",
    "            #propernouns = [word for word,pos in tagged_sent if pos == 'NNP']\n",
    "            for noun in named_entities:\n",
    "                if noun not in top_word:\n",
    "                    top_word[noun] = 1\n",
    "                else:\n",
    "                    top_word[noun] = top_word[noun] + 1\n",
    "            #print(propernouns)\n",
    "    #sorted_top_words = sorted(top_word.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    sorted_top_words = [(k, top_word[k]) for k in sorted(top_word, key=top_word.get, reverse=True)]\n",
    "    sports_results[sport] = sorted_top_words[:MAX_RESULTS]\n",
    "    \n",
    "#print(sports_results)\n",
    "print(\"Most discussed people in each sports in New York Times\")\n",
    "for sport,people in sports_results.items():\n",
    "    print(\"\\n\"+sport+\":\")\n",
    "    for person in people:\n",
    "        print(str(person[1])+\" - \"+person[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
